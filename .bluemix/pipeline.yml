---
defaultBaseImageVersion: latest
properties:
- name: IBM_CLOUD_API_KEY
  value: ${API_KEY}
  type: secure
stages:
- name: Build Stage
  inputs:
  - type: git
    branch: master
    service: ${GIT_REPO}
  triggers:
  - type: commit
  properties:
  - name: IMAGE_NAME
    value: ${IMAGE_NAME}
    type: text
  - name: APP_PORT
    value: ${APP_PORT}
    type: text
  - name: KUBECTL_VERSION
    value: v1.13.3
    type: text
  - name: KUBECTL_DOWNLOAD_URL
    value: https://storage.googleapis.com/kubernetes-release/release/v1.13.3/bin/linux/amd64/kubectl
    type: text
  jobs:
  - name: Build
    type: builder
    build_type: cr
    artifact_dir: ''
    target:
      region_id: ${PROD_REGION_ID}
      api_key: ${API_KEY}
    namespace: ${REGISTRY_NAMESPACE}
    image_name: ${IMAGE_NAME}
    script: |-
      #!/bin/bash

      mkdir downloads
      PATH="downloads:$PATH"
      echo "kubectl version"
      kubectl version --client

      echo "Build environment variables:"
      echo "REGISTRY_URL=${REGISTRY_URL}"
      echo "REGISTRY_NAMESPACE=${REGISTRY_NAMESPACE}"
      echo "IMAGE_NAME=${IMAGE_NAME}"
      echo "BUILD_NUMBER=${BUILD_NUMBER}"
      echo "ARCHIVE_DIR=${ARCHIVE_DIR}"
      echo "APP_PORT=${APP_PORT}"

      # also run 'env' command to find all available env variables
      # or learn more about the available environment variables at:
      # https://cloud.ibm.com/docs/services/ContinuousDelivery/pipeline_deploy_var.html#deliverypipeline_environment

      # To review or change build options use:
      # ibmcloud cr build --help

      echo "Checking registry namespace: ${REGISTRY_NAMESPACE}"
      NS=$( ibmcloud cr namespaces | grep ${REGISTRY_NAMESPACE} ||: )
      if [ -z "${NS}" ]; then
          echo -e "Registry namespace ${REGISTRY_NAMESPACE} not found, creating it."
          ibmcloud cr namespace-add ${REGISTRY_NAMESPACE}
          echo -e "Registry namespace ${REGISTRY_NAMESPACE} created."
      else
          echo -e "Registry namespace ${REGISTRY_NAMESPACE} found."
      fi

      echo -e "Existing images in registry"

      echo "=========================================================="
      echo -e "BUILDING CONTAINER IMAGE: ${IMAGE_NAME}:${BUILD_NUMBER}"
      set -x
      ibmcloud cr build -t ${REGISTRY_URL}/${REGISTRY_NAMESPACE}/${IMAGE_NAME}:${BUILD_NUMBER} .
      ibmcloud cr image-tag ${REGISTRY_URL}/${REGISTRY_NAMESPACE}/${IMAGE_NAME}:${BUILD_NUMBER} \
          ${REGISTRY_URL}/${REGISTRY_NAMESPACE}/${IMAGE_NAME}:latest

      set +x
      ibmcloud cr image-inspect ${REGISTRY_URL}/${REGISTRY_NAMESPACE}/${IMAGE_NAME}:${BUILD_NUMBER}

      export PIPELINE_IMAGE_URL="$REGISTRY_URL/$REGISTRY_NAMESPACE/$IMAGE_NAME:$BUILD_NUMBER"

      echo "=========================================================="
      echo "COPYING ARTIFACTS needed for deployment and testing (in particular build.properties)"

      echo "Checking archive dir presence"
      mkdir -p $ARCHIVE_DIR

      # Persist env variables into a properties file (build.properties) so that all pipeline stages consuming this
      # build as input and configured with an environment properties file valued 'build.properties'
      # will be able to reuse the env variables in their job shell scripts.

      # IMAGE information from build.properties is used in Helm Chart deployment to set the release name
      echo "IMAGE_NAME=${IMAGE_NAME}" >> $ARCHIVE_DIR/build.properties
      echo "BUILD_NUMBER=${BUILD_NUMBER}" >> $ARCHIVE_DIR/build.properties
      # REGISTRY information from build.properties is used in Helm Chart deployment to generate cluster secret
      echo "REGISTRY_URL=${REGISTRY_URL}" >> $ARCHIVE_DIR/build.properties
      echo "REGISTRY_NAMESPACE=${REGISTRY_NAMESPACE}" >> $ARCHIVE_DIR/build.properties
      echo "APP_PORT=${APP_PORT}" >> $ARCHIVE_DIR/build.properties

      echo "File 'build.properties' created for passing env variables to subsequent pipeline jobs:"
      cat $ARCHIVE_DIR/build.properties

      echo "Copy pipeline scripts along with the build"
      # Copy scripts (incl. deploy scripts)
      if [ -d ./scripts/ ]; then
        if [ ! -d $ARCHIVE_DIR/scripts/ ]; then # no need to copy if working in ./ already
          cp -r ./scripts/ $ARCHIVE_DIR/
        fi
      fi

      if  [[ -f post_build.sh ]]; then
        chmod +x post_build.sh;
        echo "executing the post_build script";
        sh post_build.sh;
      else
        echo "the post_build script does not exist";
      fi
- name: Deploy Stage
  inputs:
  - type: job
    stage: Build Stage
    job: Build
  triggers:
  - type: stage
  properties:
  - name: buildProperties
    value: build.properties
    type: file
  - name: CLUSTER_NAMESPACE
    value: ${PROD_CLUSTER_NAMESPACE}
    type: text
  - name: SERVICE_FILE_UPDATE_INSTRUCTIONS
    value:
      $text: service_update_instructions.yml
    type: text
  - name: SERVICE_FILE
    value: service.yml
    type: text
  - name: SERVICE_FILE_UPDATE_INSTRUCTIONS_FILE
    value: service_update_instructions.yml
    type: text
  jobs:
  - name: Deploy
    type: deployer
    deploy_type: kubernetes
    target:
      application: ${CF_APP}
      api_key: ${API_KEY}
      region_id: ${PROD_REGION_ID}
      kubernetes_cluster: ${PROD_CLUSTER_NAME}
    script: |-
      #!/bin/bash
      export PATH="downloads:$PATH"

      #View build properties
      cat build.properties

      echo "Check cluster availability"
      IP_ADDR=$(ibmcloud cs workers ${PIPELINE_KUBERNETES_CLUSTER_NAME} | grep normal | head -n 1 | awk '{ print $2 }')
      if [ -z $IP_ADDR ]; then
          echo "$PIPELINE_KUBERNETES_CLUSTER_NAME not created or workers not ready"
          exit 1
      fi

      # Check for installation of Knative addon
      echo "Check Knative availability"
      KNATIVE_INSTALLED=$(ibmcloud cs cluster addons --cluster ${PIPELINE_KUBERNETES_CLUSTER_NAME} --json | jq '.[].name?|select(. == "knative")')
      if [ -z $KNATIVE_INSTALLED ]; then
          echo "Knative is required but is not installed in this cluster. Install the Knative add-on and retry. Note that the Knative add-on is not supported on lite clusters."
          exit 1
      fi

      KNATIVE_RUNNING=$(kubectl get pods --namespace knative-serving -o json | jq '.items|length')
      if [ "0" == $KNATIVE_RUNNING ]; then
          echo "Knative is required but is not running in this cluster. Ensure that the cluster's workers meet the minimum requirements for Istio. Install the Knative add-on and retry. Note that the Knative add-on is not supported on lite clusters."
          exit 1
      fi

      echo "Configuring cluster namespace"
      if kubectl get namespace ${CLUSTER_NAMESPACE}; then
        echo -e "Namespace ${CLUSTER_NAMESPACE} found."
      else
        kubectl create namespace ${CLUSTER_NAMESPACE}
        echo -e "Namespace ${CLUSTER_NAMESPACE} created."
      fi

      echo "Configuring cluster role binding"
      if kubectl get clusterrolebinding kube-system:default; then
        echo -e "Cluster role binding found."
      else
        kubectl create clusterrolebinding kube-system:default --clusterrole=cluster-admin --serviceaccount=kube-system:default
        echo -e "Cluster role binding created."
      fi

      #Update service.yml with service and image name
      echo "=========================================================="
      echo "CHECKING SERVICE.YML manifest"
      if [ ! -f ${SERVICE_FILE} ]; then
        echo -e "Knative service file '${SERVICE_FILE}' not found. Ensure a Knative service definition file named '${SERVICE_FILE}' is located at the project's root directory. Alternatively, change the SERVICE_FILE environment property in the Deploy stage configuration."
        exit 1
      else
        echo "UPDATING service manifest with image information"
        echo "${SERVICE_FILE_UPDATE_INSTRUCTIONS}" | sed -e "s/REGISTRY_URL/${REGISTRY_URL}/g" -e "s/REGISTRY_NAMESPACE/${REGISTRY_NAMESPACE}/g" -e "s/IMAGE_NAME/${IMAGE_NAME}/g" -e "s/BUILD_NUMBER/${BUILD_NUMBER}/g" > ${SERVICE_FILE_UPDATE_INSTRUCTIONS_FILE}
        echo "Service file update instructions:"
        cat ${SERVICE_FILE_UPDATE_INSTRUCTIONS_FILE}
        IMAGE_REPOSITORY=${REGISTRY_URL}/${REGISTRY_NAMESPACE}/${IMAGE_NAME}
        echo -e "Updating ${SERVICE_FILE} with image name: ${IMAGE_REPOSITORY}"
        NEW_SERVICE_FILE=tmp.${SERVICE_FILE}
        yq write --doc 0 -s ${SERVICE_FILE_UPDATE_INSTRUCTIONS_FILE} ${SERVICE_FILE} > ${NEW_SERVICE_FILE}
        SERVICE_FILE=${NEW_SERVICE_FILE} # use modified file
      fi


      # Deploy the most recent revision of the specified image
      echo "=========================================================="
      cat ${SERVICE_FILE}
      echo "Deploying Knative service..."
      kubectl apply -f ${SERVICE_FILE}


      echo "Checking if application is ready..."
      for ITERATION in {1..30}
      do
        sleep 3

        kubectl get ksvc/${IMAGE_NAME} --output=custom-columns=DOMAIN:.status.conditions[*].status
        SVC_STATUS_READY=$( kubectl get ksvc/${IMAGE_NAME} -o json | jq '.status?.conditions[]?.status?|select(. == "True")' )
        echo SVC_STATUS_READY=$SVC_STATUS_READY

        SVC_STATUS_NOT_READY=$( kubectl get ksvc/${IMAGE_NAME} -o json | jq '.status?.conditions[]?.status?|select(. == "False")' )
        echo SVC_STATUS_NOT_READY=$SVC_STATUS_NOT_READY

        SVC_STATUS_UNKNOWN=$( kubectl get ksvc/${IMAGE_NAME} -o json | jq '.status?.conditions[]?.status?|select(. == "Unknown")' )
        echo SVC_STATUS_UNKNOWN=$SVC_STATUS_UNKNOWN

        if [ \( -n "$SVC_STATUS_NOT_READY" \) -o \( -n "$SVC_STATUS_UNKNOWN" \) ]; then
          echo "Application not ready, retrying"
        elif [ -n "$SVC_STATUS_READY" ]; then
          echo "Application is ready"
          break
        else
          echo "Application status unknown, retrying"
        fi
      done
      echo "Application service details:"
      kubectl describe ksvc/${IMAGE_NAME}
      if [ \( -n "$SVC_STATUS_NOT_READY" \) -o \( -n "$SVC_STATUS_UNKNOWN" \) ]; then
        echo "Application is not ready after waiting maximum time"
        exit 1
      fi

      # Determine app url for polling from knative service
      TEMP_URL=$( kubectl get ksvc/${IMAGE_NAME} -o json | jq '.status.url' )
      echo "Application status URL: $TEMP_URL"
      TEMP_URL=${TEMP_URL%\"} # remove end quote
      TEMP_URL=${TEMP_URL#\"} # remove beginning quote
      export APPLICATION_URL=$TEMP_URL
      if [ -z "$APPLICATION_URL" ]; then
        echo "Deploy failed, no URL found for knative service"
        exit 1
      fi
      echo "Application is available"
      echo "=========================================================="
      echo -e "View the application at: $APPLICATION_URL"

      echo "export IP_ADDR=${IP_ADDR}" >> kube_vars.sh
      echo "export PORT=${PORT}" >> kube_vars.sh
  - name: Test
    type: deployer
    deploy_type: kubernetes
    target:
      region_id: ${PROD_REGION_ID}
      api_key: ${API_KEY}
      kubernetes_cluster: ${PROD_CLUSTER_NAME}
    script: |-
      export PATH="downloads:$PATH"
      kubectl get ksvc/${IMAGE_NAME} -o json | jq '.status.url'
      TEMP_URL=$( kubectl get ksvc/${IMAGE_NAME} -o json | jq '.status.url' )
      TEMP_URL=${TEMP_URL%\"} # remove end quote
      TEMP_URL=${TEMP_URL#\"} # remove beginning quote
      export APPLICATION_URL=$TEMP_URL

      if [ "$(curl -is $APPLICATION_URL --connect-timeout 3 --max-time 5 --retry 2 --retry-max-time 30 | head -n 1 | grep 200)" != "" ]; then
        echo "Successfully reached health endpoint at $APPLICATION_URL"
        echo "====================================================================="
      elif [ "$(curl -is "$APPLICATION_URL/health" --connect-timeout 3 --max-time 5 --retry 2 --retry-max-time 30 | head -n 1 | grep 200)" != "" ]; then 
        echo "Successfully reached health endpoint at $APPLICATION_URL/health"
        echo "====================================================================="
      else
        echo "Could not reach health endpoint: $APPLICATION_URL"
        exit 1;
      fi;
